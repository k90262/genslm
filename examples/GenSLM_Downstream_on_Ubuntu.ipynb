{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFJQeb_qraNB"
   },
   "source": [
    "# Background\n",
    "\n",
    "## DNA Melting Point\n",
    "\n",
    "> Colab version: https://colab.research.google.com/drive/1YBbVp0rSQiY76YzYzlxF1gOQXBi1sc1U#scrollTo=PsDHUoNGU62n\n",
    "> \n",
    "> ----\n",
    "> Original Version: https://github.com/ramanathanlab/SciFM24-Tutorial/blob/main/notebooks/GenSLM_Downstream.ipynb\n",
    "> Original Colab: https://colab.research.google.com/github/ramanathanlab/SciFM24-Tutorial/blob/main/notebooks/GenSLM_Downstream.ipynb\n",
    "\n",
    "__Wikipedia:__\n",
    "\n",
    "Nucleic acid thermodynamics is the study of how temperature affects the nucleic acid structure of double-stranded DNA (dsDNA). The melting temperature (Tm) is defined as the temperature at which half of the DNA strands are in the random coil or single-stranded (ssDNA) state. Tm depends on the length of the DNA molecule and its specific nucleotide sequence. DNA, when in a state where its two strands are dissociated (i.e., the dsDNA molecule exists as two independent strands), is referred to as having been denatured by the high temperature.\n",
    "\n",
    "\n",
    "## This notebook\n",
    "\n",
    "In this notebook we will use the GenSLM 25M parameter langauge model to generate embeddings for sequences and use a downstream model to take the embeddings and predict the melting point of the associated sequence. This workflow is common for many bioinformatics tasks, and can easily be adapted to other regression and classification problems."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9W_LPOTOMrMs",
    "outputId": "ceaf1bd2-f13d-4f81-faa3-51c863c563c2",
    "ExecuteTime": {
     "end_time": "2024-09-04T08:56:22.127527Z",
     "start_time": "2024-09-04T08:56:21.940240Z"
    }
   },
   "source": [
    "!python --version"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.14\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PsDHUoNGU62n",
    "outputId": "16c60af5-3d13-4fd5-ec19-0f226b35657f",
    "ExecuteTime": {
     "end_time": "2024-09-04T09:11:31.196599Z",
     "start_time": "2024-09-04T09:11:18.459366Z"
    }
   },
   "source": [
    "# Installing GenSLM\n",
    "# NOTE: You may need to run this twice due env reload\n",
    "!pip install git+https://github.com/k90262/genslm"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/k90262/genslm\r\n",
      "  Cloning https://github.com/k90262/genslm to /tmp/pip-req-build-s5agt4yc\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/k90262/genslm /tmp/pip-req-build-s5agt4yc\r\n",
      "  Resolved https://github.com/k90262/genslm to commit aed33b2e1492987290559e2f2f7962e0d50aff68\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting transformers@ git+https://github.com/maxzvyagin/transformers (from genslm==0.0.4a1)\r\n",
      "  Cloning https://github.com/maxzvyagin/transformers to /tmp/pip-install-09c029wq/transformers_eee5f72e74644918afd0cd917e431be9\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/maxzvyagin/transformers /tmp/pip-install-09c029wq/transformers_eee5f72e74644918afd0cd917e431be9\r\n",
      "  Resolved https://github.com/maxzvyagin/transformers to commit ffd5aba0ad41a1ebd1897a77f6a3782fc2d75e1f\r\n",
      "  Installing build dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: pytorch-lightning==2.4.0 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from genslm==0.0.4a1) (2.4.0)\r\n",
      "Requirement already satisfied: wandb in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from genslm==0.0.4a1) (0.17.8)\r\n",
      "Requirement already satisfied: pydantic==1.10.2 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from genslm==0.0.4a1) (1.10.2)\r\n",
      "Requirement already satisfied: biopython==1.79 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from genslm==0.0.4a1) (1.79)\r\n",
      "Requirement already satisfied: pandas in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from genslm==0.0.4a1) (2.2.2)\r\n",
      "Requirement already satisfied: natsort in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from genslm==0.0.4a1) (8.4.0)\r\n",
      "Requirement already satisfied: Jinja2 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from genslm==0.0.4a1) (3.1.4)\r\n",
      "Requirement already satisfied: h5py==3.11.0 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from genslm==0.0.4a1) (3.11.0)\r\n",
      "Requirement already satisfied: lightning-transformers==0.2.1 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from genslm==0.0.4a1) (0.2.1)\r\n",
      "Requirement already satisfied: numpy in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from biopython==1.79->genslm==0.0.4a1) (1.26.3)\r\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from lightning-transformers==0.2.1->genslm==0.0.4a1) (2.4.0)\r\n",
      "Requirement already satisfied: tqdm in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from lightning-transformers==0.2.1->genslm==0.0.4a1) (4.66.5)\r\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from lightning-transformers==0.2.1->genslm==0.0.4a1) (1.4.1)\r\n",
      "Requirement already satisfied: datasets in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from lightning-transformers==0.2.1->genslm==0.0.4a1) (2.21.0)\r\n",
      "Requirement already satisfied: sentencepiece in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from lightning-transformers==0.2.1->genslm==0.0.4a1) (0.2.0)\r\n",
      "Requirement already satisfied: Pillow in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from lightning-transformers==0.2.1->genslm==0.0.4a1) (10.4.0)\r\n",
      "Requirement already satisfied: protobuf==3.20.1 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from lightning-transformers==0.2.1->genslm==0.0.4a1) (3.20.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from pydantic==1.10.2->genslm==0.0.4a1) (4.12.2)\r\n",
      "Requirement already satisfied: PyYAML>=5.4 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from pytorch-lightning==2.4.0->genslm==0.0.4a1) (6.0.2)\r\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning==2.4.0->genslm==0.0.4a1) (2024.6.1)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from pytorch-lightning==2.4.0->genslm==0.0.4a1) (24.1)\r\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from pytorch-lightning==2.4.0->genslm==0.0.4a1) (0.11.7)\r\n",
      "Requirement already satisfied: filelock in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from transformers@ git+https://github.com/maxzvyagin/transformers->genslm==0.0.4a1) (3.15.4)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from transformers@ git+https://github.com/maxzvyagin/transformers->genslm==0.0.4a1) (0.24.6)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from transformers@ git+https://github.com/maxzvyagin/transformers->genslm==0.0.4a1) (2024.7.24)\r\n",
      "Requirement already satisfied: requests in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from transformers@ git+https://github.com/maxzvyagin/transformers->genslm==0.0.4a1) (2.32.3)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from transformers@ git+https://github.com/maxzvyagin/transformers->genslm==0.0.4a1) (0.12.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from Jinja2->genslm==0.0.4a1) (2.1.5)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from pandas->genslm==0.0.4a1) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from pandas->genslm==0.0.4a1) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from pandas->genslm==0.0.4a1) (2023.3)\r\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from wandb->genslm==0.0.4a1) (8.1.7)\r\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from wandb->genslm==0.0.4a1) (0.4.0)\r\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from wandb->genslm==0.0.4a1) (3.1.43)\r\n",
      "Requirement already satisfied: platformdirs in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from wandb->genslm==0.0.4a1) (4.2.2)\r\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from wandb->genslm==0.0.4a1) (6.0.0)\r\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from wandb->genslm==0.0.4a1) (2.13.0)\r\n",
      "Requirement already satisfied: setproctitle in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from wandb->genslm==0.0.4a1) (1.3.3)\r\n",
      "Requirement already satisfied: setuptools in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from wandb->genslm==0.0.4a1) (74.1.0)\r\n",
      "Requirement already satisfied: six>=1.4.0 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb->genslm==0.0.4a1) (1.16.0)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning==2.4.0->genslm==0.0.4a1) (3.10.5)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->genslm==0.0.4a1) (4.0.11)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from requests->transformers@ git+https://github.com/maxzvyagin/transformers->genslm==0.0.4a1) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from requests->transformers@ git+https://github.com/maxzvyagin/transformers->genslm==0.0.4a1) (3.8)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from requests->transformers@ git+https://github.com/maxzvyagin/transformers->genslm==0.0.4a1) (2.2.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from requests->transformers@ git+https://github.com/maxzvyagin/transformers->genslm==0.0.4a1) (2024.8.30)\r\n",
      "Requirement already satisfied: sympy in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (1.13.2)\r\n",
      "Requirement already satisfied: networkx in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (3.3)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (9.1.0.70)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (12.1.3.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (11.0.2.54)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (10.3.2.106)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (11.4.5.107)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (12.1.0.106)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (2.20.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (12.1.105)\r\n",
      "Requirement already satisfied: triton==3.0.0 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (3.0.0)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (12.6.68)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from datasets->lightning-transformers==0.2.1->genslm==0.0.4a1) (17.0.0)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from datasets->lightning-transformers==0.2.1->genslm==0.0.4a1) (0.3.8)\r\n",
      "Requirement already satisfied: xxhash in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from datasets->lightning-transformers==0.2.1->genslm==0.0.4a1) (3.5.0)\r\n",
      "Requirement already satisfied: multiprocess in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from datasets->lightning-transformers==0.2.1->genslm==0.0.4a1) (0.70.16)\r\n",
      "Requirement already satisfied: nltk>=3.6 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from torchmetrics[text]->lightning-transformers==0.2.1->genslm==0.0.4a1) (3.9.1)\r\n",
      "Requirement already satisfied: mecab-python3>=1.0.6 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from torchmetrics[text]->lightning-transformers==0.2.1->genslm==0.0.4a1) (1.0.9)\r\n",
      "Requirement already satisfied: ipadic>=1.0.0 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from torchmetrics[text]->lightning-transformers==0.2.1->genslm==0.0.4a1) (1.0.0)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.4.0->genslm==0.0.4a1) (2.4.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.4.0->genslm==0.0.4a1) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.4.0->genslm==0.0.4a1) (24.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.4.0->genslm==0.0.4a1) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.4.0->genslm==0.0.4a1) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.4.0->genslm==0.0.4a1) (1.9.7)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.4.0->genslm==0.0.4a1) (4.0.3)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->genslm==0.0.4a1) (5.0.1)\r\n",
      "Requirement already satisfied: joblib in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from nltk>=3.6->torchmetrics[text]->lightning-transformers==0.2.1->genslm==0.0.4a1) (1.4.2)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ycho/anaconda3/envs/genslm/lib/python3.10/site-packages (from sympy->torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (1.3.0)\r\n",
      "Building wheels for collected packages: genslm\r\n",
      "  Building wheel for genslm (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for genslm: filename=genslm-0.0.4a1-py3-none-any.whl size=65637 sha256=f4df2a98e0d77f2b9c103e4cb1e15f9f310cc7a597e85c3b20c917d723a22bff\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-mdp861ps/wheels/8b/b4/b4/c56c40986ce6c695be26ea74a07101919df4b02e8066744112\r\n",
      "Successfully built genslm\r\n",
      "Installing collected packages: genslm\r\n",
      "  Attempting uninstall: genslm\r\n",
      "    Found existing installation: genslm 0.0.4a1\r\n",
      "    Uninstalling genslm-0.0.4a1:\r\n",
      "      Successfully uninstalled genslm-0.0.4a1\r\n",
      "Successfully installed genslm-0.0.4a1\r\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2Y9RyjnkdsUY",
    "ExecuteTime": {
     "end_time": "2024-09-04T09:30:20.890858Z",
     "start_time": "2024-09-04T09:30:19.669910Z"
    }
   },
   "source": [
    "# Note 1: (not sure) re-install `pip install numpy==1.26.3` once facing any numpy array issues\n",
    "# Note 2: we can run below command cell one by one via iPython (not must need on JupterServer)\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn import svm\n",
    "#from google.colab import drive\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from genslm import GenSLM, SequenceDataset"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNXGN5fTV65k"
   },
   "source": [
    "# Aquiring Model and Data\n",
    "\n",
    "Visit: https://drive.google.com/drive/folders/1oYgda4Px-tugapgE2uumiUIf2p3PqIQI?usp=drive_link\n",
    "\n",
    "- Right click `UmichSciFM-2024` Folder and click Organize -> Add Shortcut -> All Locations -> My Drive\n",
    "\n",
    "Executing the cell below mounts your Google Drive to this notebook giving you access to the model checkpoint and data for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "17wF__wFLl9_",
    "outputId": "737501e1-87a2-4263-d8aa-52aebd420b36",
    "ExecuteTime": {
     "end_time": "2024-09-04T09:31:11.577197Z",
     "start_time": "2024-09-04T09:31:11.387584Z"
    }
   },
   "source": [
    "# Mount and see file structure\n",
    "#drive.mount(\"/content/drive\")\n",
    "\n",
    "!ls ~/Projects/UMichSciFM-2024"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  model\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "8gGfdw6Ya3SN",
    "outputId": "99e4b0c5-57b9-4f6b-a9c6-1a995df7c01d",
    "ExecuteTime": {
     "end_time": "2024-09-04T09:31:13.256275Z",
     "start_time": "2024-09-04T09:31:13.199680Z"
    }
   },
   "source": [
    "# Load and view the dataset, split into train/test\n",
    "data = pd.read_csv(\"~/Projects/UMichSciFM-2024/data/meltingpoint.csv\", index_col=0)\n",
    "data"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               Sequence  MeltingPoint\n",
       "0     atgattatttccgcagccagcgattatcgcgccgcagcacaacgca...     82.112491\n",
       "1     atggctaagctgaccaagcgcatgcgcgtgatccgtgacaaagttg...     80.338892\n",
       "2     atgtttaaaaataaaatgatgatttgtctttatatgtttctattat...     76.102904\n",
       "3     atgggtcgactggaaggaaaggtagcgatcgtcacgggcggtgcgc...     86.743695\n",
       "4     atgcgtctaaaccccggccaacaacaagctgtcgaattcgttaccg...     81.709235\n",
       "...                                                 ...           ...\n",
       "9411  gtggatatgagtaatacaagtgcagcaccacgtgacacgtgggggt...     78.878742\n",
       "9412  ttggttgagcgccacgacatcgcaaccggtgccaccgggcgtaacc...     82.666703\n",
       "9413  atgttccgttcgcttcttcgcctgtctgcagcgttgctggccttga...     85.151774\n",
       "9414  gtgaaattactagatttattgtcaaaaggaattgtaataggtgatg...     75.071559\n",
       "9415  gtggaaatgtcacaactttcaccacgccgtccgtatctgctgcgcg...     81.473411\n",
       "\n",
       "[9416 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "      <th>MeltingPoint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>atgattatttccgcagccagcgattatcgcgccgcagcacaacgca...</td>\n",
       "      <td>82.112491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atggctaagctgaccaagcgcatgcgcgtgatccgtgacaaagttg...</td>\n",
       "      <td>80.338892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>atgtttaaaaataaaatgatgatttgtctttatatgtttctattat...</td>\n",
       "      <td>76.102904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>atgggtcgactggaaggaaaggtagcgatcgtcacgggcggtgcgc...</td>\n",
       "      <td>86.743695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>atgcgtctaaaccccggccaacaacaagctgtcgaattcgttaccg...</td>\n",
       "      <td>81.709235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9411</th>\n",
       "      <td>gtggatatgagtaatacaagtgcagcaccacgtgacacgtgggggt...</td>\n",
       "      <td>78.878742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9412</th>\n",
       "      <td>ttggttgagcgccacgacatcgcaaccggtgccaccgggcgtaacc...</td>\n",
       "      <td>82.666703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9413</th>\n",
       "      <td>atgttccgttcgcttcttcgcctgtctgcagcgttgctggccttga...</td>\n",
       "      <td>85.151774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9414</th>\n",
       "      <td>gtgaaattactagatttattgtcaaaaggaattgtaataggtgatg...</td>\n",
       "      <td>75.071559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9415</th>\n",
       "      <td>gtggaaatgtcacaactttcaccacgccgtccgtatctgctgcgcg...</td>\n",
       "      <td>81.473411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9416 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qNHyufydcKy4",
    "ExecuteTime": {
     "end_time": "2024-09-04T09:31:15.907741Z",
     "start_time": "2024-09-04T09:31:15.902755Z"
    }
   },
   "source": [
    "# Split dataset for use later\n",
    "\n",
    "# Returns two independent dataframes that we will use for\n",
    "# melting point modelling\n",
    "train, test = train_test_split(data, train_size=1000, test_size=200)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Begin Modelling\n",
    "\n",
    "Below is an example of generating embeddings with GenSLM-25M, we will follow this generat workflow to generate embeddings for our dataset, and use a downstream model to predict the melting point of an input sequence"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T09:31:20.662884Z",
     "start_time": "2024-09-04T09:31:18.608209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# PREREQUISITES for using nvidia gpu: Setup cuda (my case as an example: GPU nvidia 1650 + win 11):\n",
    "# ref. which said we still be able to run pytorch with cuda on this GPU 1650, even if this gpu only support on cuda 7.5: \n",
    "#   https://discuss.pytorch.org/t/is-there-a-table-which-shows-the-supported-cuda-version-for-every-pytorch-version/105846\n",
    "# step 1. install cuda sdk 12\n",
    "#   https://developer.nvidia.com/cuda-downloads?target_os=Windows&target_arch=x86_64&target_version=11&target_type=exe_local\n",
    "# step 2. install pytorch which support cuda sdk 12.4 `conda install pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch -c nvidia`\n",
    "#   https://discuss.pytorch.org/t/is-there-a-table-which-shows-the-supported-cuda-version-for-every-pytorch-version/105846/8\n",
    "# step 3. test. Re-start iPyhton, then test `import torch` and `torch.cuda.is_available()`.\n",
    "#  it should return True\n",
    "# done.\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NH_WlPYNXhq2",
    "outputId": "806faacb-c411-4370-919e-530349726327",
    "ExecuteTime": {
     "end_time": "2024-09-04T09:31:22.718903Z",
     "start_time": "2024-09-04T09:31:21.838128Z"
    }
   },
   "source": [
    "# hotfix issue run on windows (See: https://github.com/ultralytics/yolov5/issues/10240)\n",
    "#import pathlib\n",
    "#temp = pathlib.PosixPath\n",
    "#pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "# Load model\n",
    "model = GenSLM(\"genslm_25M_patric\", model_cache_dir=\"/home/ycho/Projects/UMichSciFM-2024/model\")\n",
    "model.eval()\n",
    "\n",
    "# Select GPU device if it is available, else use CPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "# Input data is a list of gene sequences\n",
    "sequences = [\n",
    "    \"ATGAAAGTAACCGTTGTTGGAGCAGGTGCAGTTGGTGCAAGTTGCGCAGAATATATTGCA\",\n",
    "    \"ATTAAAGATTTCGCATCTGAAGTTGTTTTGTTAGACATTAAAGAAGGTTATGCCGAAGGT\",\n",
    "]\n",
    "\n",
    "example_dataset = SequenceDataset(sequences, model.seq_length, model.tokenizer)\n",
    "example_dataloader = DataLoader(example_dataset, batch_size =2)\n",
    "\n",
    "# Compute averaged-embeddings for each input sequence\n",
    "embeddings = []\n",
    "with torch.no_grad():\n",
    "    for batch in example_dataloader:\n",
    "        outputs = model(\n",
    "            batch[\"input_ids\"].to(device),\n",
    "            batch[\"attention_mask\"].to(device),\n",
    "            output_hidden_states=True,\n",
    "        )\n",
    "        # outputs.hidden_states shape: (layers, batch_size, sequence_length, hidden_size)\n",
    "        # Use the embeddings of the last layer\n",
    "        emb = outputs.hidden_states[-1].detach().cpu().numpy()\n",
    "        # Compute average over sequence length\n",
    "        emb = np.mean(emb, axis=1)\n",
    "        embeddings.append(emb)\n",
    "\n",
    "# Concatenate embeddings into an array of shape (num_sequences, hidden_size)\n",
    "embeddings = np.concatenate(embeddings)\n",
    "embeddings.shape"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycho/PycharmProjects/genslm/genslm/inference.py:96: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ptl_checkpoint = torch.load(weight_path, map_location=\"cpu\")\n",
      "Tokenizing...: 100%|██████████| 2/2 [00:00<00:00, 599.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 512)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xG66v3y6YzHj",
    "outputId": "b8064dac-4e75-4c93-8d49-dd38d9fd2474",
    "ExecuteTime": {
     "end_time": "2024-09-04T09:32:45.988778Z",
     "start_time": "2024-09-04T09:31:54.648072Z"
    }
   },
   "source": [
    "# Get embeddings for training dataset\n",
    "train_dataset = SequenceDataset(train.Sequence.values, model.seq_length, model.tokenizer)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8)\n",
    "\n",
    "# Compute averaged-embeddings for each input sequence\n",
    "train_embeddings = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(train_dataloader, desc=\"Embedding\"):\n",
    "        outputs = model(\n",
    "            batch[\"input_ids\"].to(device),\n",
    "            batch[\"attention_mask\"].to(device),\n",
    "            output_hidden_states=True,\n",
    "        )\n",
    "        # outputs.hidden_states shape: (layers, batch_size, sequence_length, hidden_size)\n",
    "        # Use the embeddings of the last layer\n",
    "        emb = outputs.hidden_states[-1].detach().cpu().numpy()\n",
    "        # Compute average over sequence length\n",
    "        emb = np.mean(emb, axis=1)\n",
    "        train_embeddings.append(emb)\n",
    "\n",
    "# Concatenate embeddings into an array of shape (num_sequences, hidden_size)\n",
    "train_embeddings = np.concatenate(train_embeddings)\n",
    "train_embeddings.shape"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing...: 100%|██████████| 1000/1000 [00:00<00:00, 1585.82it/s]\n",
      "Embedding: 100%|██████████| 125/125 [00:50<00:00,  2.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1000, 512)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "T99uwyOOcxXF",
    "outputId": "1963aa18-5706-4867-bf3d-4a462592052a",
    "ExecuteTime": {
     "end_time": "2024-09-04T09:33:04.153183Z",
     "start_time": "2024-09-04T09:33:04.064024Z"
    }
   },
   "source": [
    "# Train SVM on embeddings for melting point\n",
    "mp_regr = svm.SVR()\n",
    "mp_regr.fit(train_embeddings, train.MeltingPoint.values)\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR()"
      ],
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVR()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR()</pre></div></div></div></div></div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oB-6ezWfha_6"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nRGswn1OhNMj",
    "outputId": "b4b5c149-3052-4b32-a326-855571bacaac",
    "ExecuteTime": {
     "end_time": "2024-09-04T09:33:17.012960Z",
     "start_time": "2024-09-04T09:33:06.708057Z"
    }
   },
   "source": [
    "# Get embeddings for evaluation dataset\n",
    "test_dataset = SequenceDataset(test.Sequence.values, model.seq_length, model.tokenizer)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8)\n",
    "\n",
    "# Compute averaged-embeddings for each input sequence\n",
    "test_embeddings = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader, desc=\"Embedding\"):\n",
    "        outputs = model(\n",
    "            batch[\"input_ids\"].to(device),\n",
    "            batch[\"attention_mask\"].to(device),\n",
    "            output_hidden_states=True,\n",
    "        )\n",
    "        # outputs.hidden_states shape: (layers, batch_size, sequence_length, hidden_size)\n",
    "        # Use the embeddings of the last layer\n",
    "        emb = outputs.hidden_states[-1].detach().cpu().numpy()\n",
    "        # Compute average over sequence length\n",
    "        emb = np.mean(emb, axis=1)\n",
    "        test_embeddings.append(emb)\n",
    "\n",
    "# Concatenate embeddings into an array of shape (num_sequences, hidden_size)\n",
    "test_embeddings = np.concatenate(test_embeddings)\n",
    "test_embeddings.shape"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing...: 100%|██████████| 200/200 [00:00<00:00, 1543.43it/s]\n",
      "Embedding: 100%|██████████| 25/25 [00:10<00:00,  2.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(200, 512)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kPCYHM5dhi7N",
    "outputId": "325b8f74-b223-4264-d271-064b2bb6adc8",
    "ExecuteTime": {
     "end_time": "2024-09-04T09:33:19.804107Z",
     "start_time": "2024-09-04T09:33:19.771218Z"
    }
   },
   "source": [
    "# Evaluate the performance of the regressor on a held out test set\n",
    "\n",
    "r2 = mp_regr.score(test_embeddings, test.MeltingPoint.values)\n",
    "\n",
    "print(f\"Regressor R^2 {r2} for test set\")\n",
    "\n",
    "# Test a few examples and see predictions\n",
    "example_predictions = mp_regr.predict(test_embeddings[:10])\n",
    "\n",
    "for (idx, row), pred_val in zip(test.iterrows(), example_predictions):\n",
    "  print(f\"Empirical melting point: {row['MeltingPoint']:.3f}\\t\\tPredicted melting point: {pred_val:.3f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressor R^2 0.9642557756833422 for test set\n",
      "Empirical melting point: 83.244\t\tPredicted melting point: 83.645\n",
      "Empirical melting point: 76.045\t\tPredicted melting point: 75.565\n",
      "Empirical melting point: 82.769\t\tPredicted melting point: 82.231\n",
      "Empirical melting point: 82.510\t\tPredicted melting point: 83.137\n",
      "Empirical melting point: 82.753\t\tPredicted melting point: 82.334\n",
      "Empirical melting point: 87.889\t\tPredicted melting point: 88.329\n",
      "Empirical melting point: 86.236\t\tPredicted melting point: 86.454\n",
      "Empirical melting point: 71.400\t\tPredicted melting point: 73.110\n",
      "Empirical melting point: 86.344\t\tPredicted melting point: 86.159\n",
      "Empirical melting point: 77.683\t\tPredicted melting point: 76.943\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
